{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2 Pr√°cticas LC. Curso 2020-2021\n",
    "### Jaime Ferrando Huertas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to /Users/jaime/nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPORTS\n",
    "import nltk\n",
    "from nltk.corpus import cess_esp\n",
    "from nltk.tag import hmm\n",
    "from nltk.tag import tnt\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "nltk.download('cess_esp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentnces: 6030\n",
      "number of words: 6030\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el corpus\n",
    "\n",
    "corpus_sentences = cess_esp.tagged_sents()\n",
    "number_sentences = len(corpus_sentences)\n",
    "print(\"number of sentnces:\", number_sentences)\n",
    "print(\"number of words:\", number_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-842112df7cdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Procesamos el corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprocessed_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtmp_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "#Procesamos el corpus\n",
    "processed_corpus = []\n",
    "for sentence in corpus:\n",
    "    tmp_sentence = []\n",
    "    for word in sentence:\n",
    "        if word[0] == \"*0*\":\n",
    "            continue\n",
    "        if word[1][0] == \"v\" or \"F\":\n",
    "            new_word = (word[0], word[1][:3])\n",
    "        else:\n",
    "            new_word = (palabra_etiquetada[0], word[1][:2])\n",
    "        tmp_sentence.append(new_word)\n",
    "    processed_corpus.append(tmp_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos el corpus en 90% training 10% test\n",
    "\n",
    "len_training = int(0.9*len(processed_corpus))\n",
    "training_notcv = processed_corpus[:len_training]\n",
    "test_notcv = processed_corpus[len_training:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamos los etiquetadores morfosintacticos (modelos HMM Y TNT) en las particiones de entranimiento previamente hechas en el ejercicio 1 ya procesadas\n",
    "\n",
    "#TNT\n",
    "tagger_tnt = tnt.TnT()\n",
    "tagger_tnt.train(training_notcv)\n",
    "v=tagger_tnt.evaluate(test_notcv)\n",
    "d = 1.96*math.sqrt((v*(1-v))/len(test_notcv))\n",
    "ic = [round(v-d,3),round(v+d, 3)]\n",
    "print(\"Precission for TNT without CV\")\n",
    "print(v)\n",
    "print(f\"Intervalo de confianza {ic}\")\n",
    "\n",
    "#HMM \n",
    "tagger_hmm = hmm.HiddenMarkovModelTagger.train(training_notcv)\n",
    "v = tagger_hmm.evaluate(test_notcv)\n",
    "d = 1.96*math.sqrt((v*(1-v))/len(test_notcv))\n",
    "ic = [round(v-d,3),round(v+d, 3)]\n",
    "print(\"Precission for HMM without CV\")\n",
    "print(v)\n",
    "print(f\"Intervalo de confianza {ic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El etiquetador basado en cadenas de markov nos da un valor de precision superior al etiquetador TNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercico 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Entrenamos los etiquetadores morfosintacticos (modelos HMM Y TNT) esta vez con el metodo de cross validation con 10-Fold, primero sin barajar el dataset y despues barajandolo\n",
    "\n",
    "#Sin barajar\n",
    "results_unshuffled_tnt = []\n",
    "results_unshuffled_hmm = []\n",
    "intervals_unshuffled_tnt = []\n",
    "intervals_unshuffled_hmm = []\n",
    "kf_unshuffled = KFold(n_splits=10, shuffle=False)\n",
    "for train_index, test_index in kf_unshuffled.split(processed_corpus):\n",
    "    #Split data\n",
    "    training_cv = np.take(processed_corpus,train_index)\n",
    "    test_cv = np.take(processed_corpus,test_index)\n",
    "    #TNT\n",
    "    tagger_tnt = tnt.TnT()\n",
    "    tagger_tnt.train(training_cv)\n",
    "    v=tagger_tnt.evaluate(test_cv)\n",
    "    results_unshuffled_tnt.append(v)\n",
    "    #Intervalos\n",
    "    d = 1.96*math.sqrt((v*(1-v))/len(test_cv))\n",
    "    ic = round(d,3)\n",
    "    intervals_unshuffled_tnt.append(ic)\n",
    "    #HMM\n",
    "    tagger_hmm = hmm.HiddenMarkovModelTagger.train(training_cv)\n",
    "    v = tagger_hmm.evaluate(test_cv)\n",
    "    results_unshuffled_hmm.append(v)\n",
    "    #Intervalos\n",
    "    d = 1.96*math.sqrt((v*(1-v))/len(test_cv))\n",
    "    ic = round(d,3)\n",
    "    intervals_unshuffled_hmm.append(ic)\n",
    "\n",
    "\n",
    "#Barajando\n",
    "kf_shuffled = KFold(n_splits=10, shuffle=True)\n",
    "results_shuffled_tnt = []\n",
    "results_shuffled_hmm = []\n",
    "intervals_shuffled_tnt = []\n",
    "intervals_shuffled_hmm = []\n",
    "for train_index, test_index in kf_shuffled.split(processed_corpus):\n",
    "    #Split data\n",
    "    training_cv = np.take(processed_corpus,train_index)\n",
    "    test_cv = np.take(processed_corpus,test_index)\n",
    "    #TNT\n",
    "    tagger_tnt = tnt.TnT()\n",
    "    tagger_tnt.train(training_cv)\n",
    "    v=tagger_tnt.evaluate(test_cv)\n",
    "    results_shuffled_tnt.append(v)\n",
    "    #Intervalos\n",
    "    d = 1.96*math.sqrt((v*(1-v))/len(test_cv))\n",
    "    ic = round(d,3)\n",
    "    intervals_shuffled_tnt.append(ic)\n",
    "    #HMM\n",
    "    tagger_hmm = hmm.HiddenMarkovModelTagger.train(training_cv)\n",
    "    v = tagger_hmm.evaluate(test_cv)\n",
    "    results_shuffled_hmm.append(v)\n",
    "    #Intervalos\n",
    "    d = 1.96*math.sqrt((v*(1-v))/len(test_cv))\n",
    "    ic = round(d,3)\n",
    "    intervals_shuffled_hmm.append(ic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos tablas y comentamos los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unshuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#TNT\n",
    "\n",
    "x=[i for i in range(10)]\n",
    "y=results_unshuffled_tnt # results es una lista con los resultados de cada experimento\n",
    "plt.axis([-1, 10, 0.80, 0.97])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Fold')\n",
    "plt.title('Cross validation 10 Folds TNT - Corpus unshuffled')\n",
    "plt.plot(x,y,'ro')\n",
    "Tic=intervals_unshuffled_tnt# Lista con los intervalos de confianza\n",
    "plt.errorbar(x,y,yerr=Tic,linestyle='None')\n",
    "plt.show()\n",
    "plt.savefig('cv_tnt_unshuffled.png')\n",
    "\n",
    "#HMM\n",
    "\n",
    "x=[i for i in range(10)]\n",
    "y=results_unshuffled_hmm # results es una lista con los resultados de cada experimento\n",
    "plt.axis([-1, 10, 0.80, 0.97])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Fold')\n",
    "plt.title('Cross validation 10 Folds HMM - Corpus unshuffled')\n",
    "plt.plot(x,y,'ro')\n",
    "Tic=intervals_unshuffled_hmm# Lista con los intervalos de confianza\n",
    "plt.errorbar(x,y,yerr=Tic,linestyle='None')\n",
    "plt.show()\n",
    "plt.savefig('cv_hmm_unshuffled.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar como para nuestros dos etiquetadores (TNT y HMM) obtienen una mejor accuracy media con cross validation que en el primer ejercicio donde tenian valores peores (TNT: 0.82, HMM: 0.88). El haber evaluado con cross validation (sin barajar) tambien nos da la oportunidad de ver como se distribuye el error de nuestro etiquetador a lo largo del dataset, vemos como el ultimo 10% del dataset es el punto con peor accuracy para los dos etiquetadores y creemos que esto se debe a que contiene muestras no muy similares al 90% inicial de los datos y por lo tanto el etiquetador no puede aprender sobre este nuevo tipo de muestras.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TNT\n",
    "x=[i for i in range(10)]\n",
    "y=results_shuffled_tnt # results es una lista con los resultados de cada experimento\n",
    "plt.axis([-1, 10, 0.80, 0.97])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Fold')\n",
    "plt.title('Cross validation 10 Folds TNT - Corpus shuffled')\n",
    "plt.plot(x,y,'ro')\n",
    "Tic=intervals_shuffled_tnt# Lista con los intervalos de confianza\n",
    "plt.errorbar(x,y,yerr=Tic,linestyle='None')\n",
    "plt.show()\n",
    "plt.savefig('cv_tnt_shuffled.png')\n",
    "\n",
    "#HMM\n",
    "\n",
    "x=[i for i in range(10)]\n",
    "y=results_shuffled_hmm # results es una lista con los resultados de cada experimento\n",
    "plt.axis([-1, 10, 0.80, 0.97])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Fold')\n",
    "plt.title('Cross validation 10 Folds HMM - Corpus shuffled')\n",
    "plt.plot(x,y,'ro')\n",
    "Tic=intervals_shuffled_hmm# Lista con los intervalos de confianza\n",
    "plt.errorbar(x,y,yerr=Tic,linestyle='None')\n",
    "plt.show()\n",
    "plt.savefig('cv_hmm_shuffled.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo si barajamos el dataset nos libramos de este inconveniente ya que teoricamente todas las muestras tienen una representacion equitativa en todos los Folds de cross validation, esto se refleja en las dos ultimas graficas donde vemos un error similar durante todos los folds de nuestro cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

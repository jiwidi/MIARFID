{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 943 users, 1682 movies, 80000 ratings\n"
     ]
    }
   ],
   "source": [
    "from os import sep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from classes import User, Movie\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "\n",
    "# Genres\n",
    "generos = pd.read_csv(\"data/genre.txt\", names=[\"genre_id\", \"genre_name\"], sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Read users\n",
    "users_df = pd.read_csv(\n",
    "    \"data/users.txt\", names=[\"user_id\", \"edad\", \"gender\", \"occupation\"], sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Read movies\n",
    "all_genre = generos.genre_name.values.tolist()\n",
    "all_genre = [\"movie_id\"] + all_genre + [\"title\"]\n",
    "films = []\n",
    "films_df = pd.read_csv(\"data/items.txt\", names=all_genre, sep=\"\\t\")\n",
    "for idx, row in films_df.iterrows():\n",
    "    films.append(Movie(row[\"movie_id\"], row[all_genre].values.tolist(), row[\"title\"]))\n",
    "\n",
    "\n",
    "# Ratings\n",
    "ratings = pd.read_csv(\n",
    "    \"data/u1_base.txt\", names=[\"user_id\", \"movie_id\", \"rating\"], sep=\"\\t\"\n",
    ")\n",
    "\n",
    "ratings = ratings.merge(users_df, on=\"user_id\")\n",
    "print(f\"Data: {len(users_df)} users, {len(films_df)} movies, {len(ratings)} ratings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Demographic recos\n",
    "def recommend_me_demographic(user,n):\n",
    "    user = users_df[users_df[\"user_id\"]==user]\n",
    "\n",
    "    # Search for films seen by this profession\n",
    "    aux_ratings = ratings[ratings[\"occupation\"] == user.occupation.values[0]]\n",
    "    aux_ratings = ratings[ratings[\"gender\"] == user.gender.values[0]]\n",
    "    aux_ratings = (\n",
    "        aux_ratings[[\"movie_id\", \"rating\"]]\n",
    "        .groupby(\"movie_id\")\n",
    "        .agg(count=(\"rating\", \"count\"), mean=(\"rating\", \"mean\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "    C = aux_ratings[\"mean\"].mean()\n",
    "    M = aux_ratings[\"count\"].quantile(0.9)\n",
    "\n",
    "    def weighted_rating(x, m=M, C=C):\n",
    "        v = x[\"count\"]\n",
    "        R = x[\"mean\"]\n",
    "        # Calculation based on the IMDB formula\n",
    "        return (v / (v + m) * R) + (m / (m + v) * C)\n",
    "\n",
    "    aux_ratings[\"score\"] = aux_ratings.apply(weighted_rating, axis=1)\n",
    "    aux_ratings = aux_ratings.merge(films_df,on=\"movie_id\")\n",
    "    # print(aux_ratings.sort_values(\"score\", ascending=False))\n",
    "    return aux_ratings.sort_values(\"score\")[\"title\"].values[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_demographic(users,n):\n",
    "    top_n = defaultdict(list)\n",
    "    for user in users:\n",
    "        recos = recommend_me_demographic(user,n)\n",
    "        top_n[user]=recos\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cable Guy, The (1996)' 'Beavis and Butt-head Do America (1996)'\n",
      " 'Vegas Vacation (1997)' 'Spawn (1997)' 'Airheads (1994)']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(recommend_me_demographic(5,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_n_demographic(users_df.user_id.unique(),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3. Collaborative Filtering\n",
    "This system matches persons with similar interests and provides recommendations based on this matching. Collaborative filters do not require item metadata like its content-based counterparts. \n",
    "\n",
    "##### Example - \n",
    "If person A likes 3 movies, say Interstellar, Inception and Predestination, and person B likes Inception, Predestination and The Prestige, then they have almost similar interests. We can say with some certainty that A should like The Prestige and B should like Interstellar. \n",
    "\n",
    "The collaborative filtering algorithm uses “User Behavior” for recommending items. This is one of the most commonly used algorithms in the industry as it is not dependent on any additional information. \n",
    "\n",
    "\n",
    "\n",
    "The collaborative filtering can be modeled in any of the following ways:-\n",
    "\n",
    "#### User-User collaborative filtering\n",
    "It finds similarity scores between users to pick the most similar users and  recommends products which these similar users have liked or bought previously.\n",
    "\n",
    "For movies, this algorithm finds the similarity between each user based on the ratings they have previously given to different movies. The prediction of an item for a user u is calculated by computing the weighted sum of the user ratings given by other users to an item i.\n",
    "Thus the prediction for user 'u' is given as:\n",
    "\n",
    "P(u,i) = E [r(v,i) * s(u,v)] / E [S(u,v)]\n",
    "\n",
    "where,\n",
    "* Pu,i is the prediction of an item\n",
    "* Rv,i is the rating given by a user v to a movie i\n",
    "* Su,v is the similarity between users\n",
    "\n",
    "Basic steps for this-\n",
    "* For predictions we need the similarity between the user u and v. We can make use of Pearson correlation.\n",
    "* First we find the items rated by both the users and based on the ratings, correlation between the users is calculated.\n",
    "* The predictions can be calculated using the similarity values. This algorithm, first of all calculates the similarity between each user and then based on each similarity calculates the predictions. Users having higher correlation will tend to be similar.\n",
    "\n",
    "\n",
    "Disadvantage-\n",
    "This algorithm is quite time consuming as it involves calculating the similarity for each user and then calculating prediction for each similarity score. One way of handling this problem is to select only a few users (neighbors) instead of all to make predictions, i.e. instead of making predictions for all similarity values, we choose only few similarity values. There are various ways to select the neighbors:\n",
    "\n",
    "* Select a threshold similarity and choose all the users above that value\n",
    "* Randomly select the users\n",
    "* Arrange the neighbors in descending order of their similarity value and choose top-N users\n",
    "* Use clustering for choosing neighbors\n",
    "\n",
    "\n",
    "\n",
    "This algorithm is useful when the number of users is less. Its not effective when there are a large number of users as it will take a lot of time to compute the similarity between all user pairs. This leads us to item-item collaborative filtering, which is effective when the number of users is more than the items being recommended.\n",
    "\n",
    "\n",
    "#### Item-Item collaborative filtering\n",
    "Similarity is found between each items. Thus for movies similarities between movies is found and based on that recommendations of similar movies are made for the user. \n",
    "\n",
    "This algorithm works similar to user-user collaborative filtering with just a little change – instead of taking the weighted sum of ratings of “user-neighbors”, we take the weighted sum of ratings of “item-neighbors”.\n",
    "\n",
    "##### What will happen if a new user or a new item is added in the dataset? \n",
    "It is called a Cold Start. \n",
    "\n",
    "* Visitor Cold Start\n",
    "Visitor Cold Start means that a new user is introduced in the dataset. Since there is no history of that user, the system does not know the preferences of that user. It becomes harder to recommend products to that user. So, how can we solve this problem? One basic approach could be to apply a popularity based strategy, i.e. recommend the most popular products. These can be determined by what has been popular recently overall or regionally. Once we know the preferences of the user, recommending products will be easier.\n",
    "\n",
    "*  Product Cold Start\n",
    "Product Cold Start means that a new product is launched in the market or added to the system. User action is most important to determine the value of any product. More the interaction a product receives, the easier it is for our model to recommend that product to the right user. We can make use of Content based filtering to solve this problem. The system first uses the content of the new product for recommendations and then eventually the user actions on that product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits = pd.read_csv(\"D:/C-Drive Project's Datasets/tmdb-5000-movie-dataset/tmdb_5000_credits.csv\")\n",
    "movies = pd.read_csv(\"data/processed/movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset, SVD, KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "reader = Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ratings = pd.read_csv(\"data/u1_base.txt\",sep=\"\\t\",names=[\"user_id\", \"movie_id\", \"rating\"])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(ratings[[\"user_id\", \"movie_id\", \"rating\"]], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = KNNBasic()\n",
    "cross_validate(svd, data, measures=['RMSE', 'MAE'],cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recos = svd.test(trainset.build_testset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = get_top_n(recos, n=10)\n",
    "\n",
    "# Print the recommended items for each user\n",
    "for uid, user_ratings in top_n.items():\n",
    "    print(uid, [iid for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For movies id = 654 we got estimated prediction of 3.83.\n",
    " \n",
    "This recommender system doesn't care what the movie is (or what it contains). It works purely on the basis of an assigned movie ID and tries to predict ratings based on how the other users have predicted the movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "We create recommenders using demographic , content- based and collaborative filtering. While demographic filtering is very elemantary and cannot be used practically, Hybrid Systems can take advantage of content-based and collaborative filtering as the two approaches are proved to be almost complimentary. This model was very baseline and only provides a fundamental framework to start with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "* https://www.kaggle.com/rounakbanik/movie-recommender-systems\n",
    "* https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-recommendation-engine-python/#\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time",
   "language": "python",
   "name": "time"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
